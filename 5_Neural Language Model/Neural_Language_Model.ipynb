{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "powered-slide",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbassignment": {
     "type": "header"
    },
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "83560d10c57e16719b86528c23a3d549",
     "grade": false,
     "grade_id": "template_886979f3_0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1>Natural Language Processing</h1>\n",
    "    Assignment 05\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Please do not add or delete any cells. Answers belong into the corresponding cells (below the question). If a function is given (either as a signature or a full function), you should not change the name, arguments or return value of the function.<br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>).</p>\n",
    "    <p>Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. If you edit the cell please outcomment or delete this line.</p>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Please submit your notebook via the web interface (in the main view -> Assignments -> Submit). The assignments are due on <b>Monday at 13:00</b>.</p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to three people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "controversial-biography",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.183088Z",
     "start_time": "2024-05-21T12:20:24.173447Z"
    },
    "nbassignment": {
     "type": "group_info"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the username of each team member into the variables. \n",
    "If you work alone please leave the other variables empty.\n",
    "'''\n",
    "member1 = 'mfarra2s'\n",
    "member2 = 'rhusai2s'\n",
    "member3 = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e82f4b5",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "849d26716a43b4837bbcdd92a049975d",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_ANeuralLanguageModel2_BNeuralLanguageModel2_CNeuralLanguageModel2_DNeuralLanguageModel2_ENeuralLanguageModel2_F_Header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Neural Language Model\n",
    "\n",
    "In this task we want to implement the neural language model given in chapter 7 of the book (p. 16) using PyTorch.\n",
    "\n",
    "<img src=\"Neural_Language_Model_files/img/model.png\">\n",
    "\n",
    "Â© Tim Metzler, Hochschule Bonn-Rhein-Sieg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9efb41",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ac50d69bde457ff1a1e71c59cb9a9ef2",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Helper Functions\n",
    "\n",
    "You are given some helper functions to make this assignment easier.\n",
    "\n",
    "First a tokenizer that turns strings into lists of token ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "22878dbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.241176Z",
     "start_time": "2024-05-21T12:20:24.188889Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00282df7b703ee93b27d41777bc6d225",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A_Description1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel\n",
    "from tokenizers.trainers import WordLevelTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from typing import List\n",
    "\n",
    "def tokenizer_from_strings(strings: List[str], vocab_size: int = None) -> Tokenizer:\n",
    "    \"\"\"\n",
    "    Create and train a WordLevel Tokenizer for tokenizing text from the given strings.\n",
    "\n",
    "    Args:\n",
    "        strings (List[str]): A list of strings containing the text data for training.\n",
    "        vocab_size (int, optional): The maximum vocabulary size to limit the number of tokens\n",
    "                                    in the tokenizer. If None, the vocabulary size is determined automatically.\n",
    "                                    Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tokenizer: A trained WordLevel Tokenizer capable of tokenizing text data.    \n",
    "    \"\"\"    \n",
    "    tokenizer = Tokenizer(WordLevel(unk_token=\"[UNK]\"))\n",
    "\n",
    "    # We can also pass a vocab_size to the trainer to only keep the most frequent words\n",
    "    # Special tokens are tokens that we want to use but are not part of the text we train on\n",
    "    trainer = WordLevelTrainer(\n",
    "        special_tokens=[\"[UNK]\", \"<s>\", \"</s>\"], \n",
    "    )\n",
    "    if vocab_size is not None:\n",
    "        trainer.vocab_size = vocab_size\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "    tokenizer.train_from_iterator(strings, trainer=trainer)\n",
    "    return tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7ce2dd3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.316871Z",
     "start_time": "2024-05-21T12:20:24.247115Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5cef62593015d9f5a1b67816c337e77b",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A_Description2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary\n",
      "{'is': 4, '</': 8, 'also': 13, 's': 5, '</s>': 2, 'But': 9, 'NLP': 12, 'It': 11, 'very': 18, 'it': 16, 'like': 17, 'I': 10, 'interesting': 15, '[UNK]': 0, '<s>': 1, '<': 7, '.': 6, 'hard': 14, '>': 3}\n",
      "\n",
      "The size of the vocabulary\n",
      "19\n",
      "\n",
      "The tokens from our input string\n",
      "['NLP', 'is', 'hard']\n",
      "\n",
      "The ids for the tokens\n",
      "[12, 4, 14]\n",
      "\n",
      "The tokens from our input string. Notice how everything unknown is represented as [UNK]\n",
      "['NLP', 'is', '[UNK]', '[UNK]', '[UNK]']\n",
      "\n",
      "The ids for the tokens\n",
      "[12, 4, 0, 0, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'. also </'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example texts for our tokenizer. This can be a list of one our more documents\n",
    "my_text = [\n",
    "    \"<s> I like NLP. </s>\",\n",
    "    \"It is very interesting\",\n",
    "    \"But it is also hard\"\n",
    "]\n",
    "\n",
    "tokenizer = tokenizer_from_strings(my_text)\n",
    "\n",
    "# Let us look at our trained vocabulary\n",
    "print(\"The vocabulary\")\n",
    "print(tokenizer.get_vocab())\n",
    "\n",
    "# Size of the vocabulary\n",
    "print(\"\\nThe size of the vocabulary\")\n",
    "print(tokenizer.get_vocab_size())\n",
    "\n",
    "# Now lets turn a sentence into a list of token indices\n",
    "encoded_input = tokenizer.encode(\"NLP is hard\")\n",
    "\n",
    "# This is how it splits it into tokens\n",
    "print(\"\\nThe tokens from our input string\")\n",
    "print(encoded_input.tokens)\n",
    "# This is how we get the ids\n",
    "print(\"\\nThe ids for the tokens\")\n",
    "print(encoded_input.ids)\n",
    "\n",
    "# Let us look what happens if we put in unknown words\n",
    "encoded_input = tokenizer.encode(\"NLP is a tough subject\")\n",
    "print(\"\\nThe tokens from our input string. Notice how everything unknown is represented as [UNK]\")\n",
    "print(encoded_input.tokens)\n",
    "print(\"\\nThe ids for the tokens\")\n",
    "print(encoded_input.ids)\n",
    "\n",
    "# Finally we can also turn back ids into strings\n",
    "tokenizer.decode([6, 13, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff0c4b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "830499bd68d9810f84975b80e6ae4cd6",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A_Description3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model A)\n",
    "### One Hot Encoder\n",
    "\n",
    "First we create a one-hot encoder that produces tensors. We will use the built-in function `torch.nn.functional.one_hot` to create our embeddings.\n",
    "\n",
    "First look at the example in the following cell.\n",
    "\n",
    "Then complete the class `OneHotEncoder` below. You need to implement the method `encode`, which encodes a single index into a one-hot embedding and the method `encode_sequence`, which will take a list of indices and should return a list of one-hot embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d955f9c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.374906Z",
     "start_time": "2024-05-21T12:20:24.327320Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c370ed4086a04e8da5657a48444a307f",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A_Description4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0.])\n",
      "torch.Size([20])\n",
      "tensor(5)\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "index = 5\n",
    "vocab_size = 20\n",
    "\n",
    "my_one_hot_embedding = one_hot(\n",
    "    tensor(index),\n",
    "    num_classes=vocab_size\n",
    ").float()\n",
    "\n",
    "print(my_one_hot_embedding)          # The embedding\n",
    "print(my_one_hot_embedding.shape)    # The size of the embedding\n",
    "print(my_one_hot_embedding.argmax()) # The index of the 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a1471dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.417088Z",
     "start_time": "2024-05-21T12:20:24.379076Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc1037869bbf31b6e712a9f984faa2f8",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_A",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "from torch import tensor, float32\n",
    "from typing import List\n",
    "\n",
    "class OneHotEncoder:\n",
    "    \n",
    "    def __init__(self, vocab_size: int):\n",
    "        \"\"\"\n",
    "        OneHotEncoder class for converting token IDs to one-hot encoded tensors.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary, i.e., the number of unique tokens.\n",
    "        \"\"\"\n",
    "        self.vocab_size = vocab_size\n",
    "        \n",
    "    def encode(self, token_id: int) -> tensor:\n",
    "        \"\"\"\n",
    "        Encode a single token ID as a one-hot encoded tensor.\n",
    "\n",
    "        Args:\n",
    "            token_id (int): The token ID to be encoded.\n",
    "\n",
    "        Returns:\n",
    "            tensor: The one-hot encoded tensor representing the input token ID.\n",
    "        \"\"\"\n",
    "        return one_hot(tensor(token_id), num_classes= self.vocab_size).float()\n",
    "    \n",
    "    def encode_sequence(self, token_ids: List[int]) -> List[tensor]:\n",
    "        \"\"\"\n",
    "        Encode a sequence of token IDs as a list of one-hot encoded tensors.\n",
    "\n",
    "        Args:\n",
    "            token_ids (List[int]): A list of token IDs to be encoded.\n",
    "\n",
    "        Returns:\n",
    "            List[tensor]: A list of one-hot encoded tensors representing the input token IDs.\n",
    "        \"\"\"\n",
    "        embedings = []\n",
    "        for ind in token_ids:\n",
    "            embedings.append(one_hot(tensor(ind), num_classes= self.vocab_size).float())\n",
    "            \n",
    "        return embedings\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9299b8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.472073Z",
     "start_time": "2024-05-21T12:20:24.423186Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cb75d514d81d6ba6e4b2d4ac5bdb0fde",
     "grade": true,
     "grade_id": "test_NeuralLanguageModel2_A0",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is for you to test if your implementation is working\n",
    "\n",
    "vocabulary_size = 50\n",
    "\n",
    "encoder = OneHotEncoder(vocabulary_size)\n",
    "\n",
    "# Test with a single index\n",
    "embedding = encoder.encode(5)\n",
    "\n",
    "assert embedding.shape[0] == vocabulary_size, \"All embeddings should have the size of the vocabulary\"\n",
    "assert embedding.argmax() == 5, \"The single one should be at index 5\"\n",
    "\n",
    "# Test with a list of indices\n",
    "indices = [5, 3, 7]\n",
    "embeddings = encoder.encode_sequence(indices)\n",
    "\n",
    "assert len(embeddings) == 3, \"We put in three indices so we want three embeddings\"\n",
    "assert isinstance(embeddings, list), \"We want to return a list\"\n",
    "\n",
    "for idx, embedding in zip(indices, embeddings):\n",
    "    assert embedding.shape[0] == vocabulary_size, \"All embeddings should have the size of the vocabulary\"\n",
    "    assert embedding.argmax() == idx, \"The single one should be at index 5\" \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237a7c19",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bda438ee4d8fbb8c43eae13a4107cb35",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_B_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model B)\n",
    "### The model\n",
    "\n",
    "Complete the model class below.\n",
    "\n",
    "**Hint: To get from three tensors of size $d$ to a tensor of size $3d$ we need to concatenate. See the next cell for an example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "827de221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.538981Z",
     "start_time": "2024-05-21T12:20:24.479183Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b945887dff3128f9807da3b84db4ef0a",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_B_Description1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([36])\n",
      "tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create our encoder and encode three indices\n",
    "encoder = OneHotEncoder(12)\n",
    "indices = [5, 3, 7]\n",
    "embedding1, embedding2, embedding3 = encoder.encode_sequence(indices)\n",
    "\n",
    "# Concatenate them into a single embedding of size 3*vocab_size\n",
    "concatenated_embeddings = torch.concatenate((embedding1, embedding2, embedding3))\n",
    "\n",
    "print(concatenated_embeddings.shape) # This is three times our vocabulary size\n",
    "print(concatenated_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "928b5ef5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.613485Z",
     "start_time": "2024-05-21T12:20:24.545778Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d4cff6bc22861264629dc8752249d7f",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_B",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import TensorType\n",
    "\n",
    "class NeuralLanguageModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A neural language model that predicts a word from two input words\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_size: int, hidden_size: int):\n",
    "        \"\"\"\n",
    "        Initializes the NeuralLanguageModel.\n",
    "\n",
    "        Args:\n",
    "            vocab_size (int): The size of the vocabulary.\n",
    "            embedding_size (int): The size of word embeddings.\n",
    "            hidden_size (int): The size of the hidden layer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create your layers here. All layers are linear\n",
    "        # We want an embedding layer\n",
    "        self.embedding = nn.Linear(self.vocab_size, self.embedding_size)\n",
    "        # Then a hidden layer\n",
    "        self.hidden = nn.Linear(3*self.embedding_size, self.hidden_size)\n",
    "        # Then an output layer\n",
    "        self.output = nn.Linear(self.hidden_size,self.vocab_size)\n",
    "        # Then we define our activation functions and the softmax\n",
    "        self.activation = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "    def forward(\n",
    "        self, \n",
    "        word1: TensorType, \n",
    "        word2: TensorType, \n",
    "        word3: TensorType, \n",
    "        inference: bool=False\n",
    "    ) -> TensorType:\n",
    "        \"\"\"\n",
    "        Forward pass of the neural language model.\n",
    "\n",
    "        Args:\n",
    "            word1 (torch.TensorType): Tensor representing the first word (one-hot).\n",
    "            word2 (torch.TensorType): Tensor representing the second word (one-hot).\n",
    "            word3 (torch.TensorType): Tensor representing the third word (one-hot).\n",
    "            inference (bool, optional): Flag representing if we are doing inference or not.\n",
    "                                        This is needed since during training PyTorch does not work well with\n",
    "                                        the softmax. \n",
    "\n",
    "        Returns:\n",
    "            torch.TensorType: Output tensor representing the probability distribution over the vocabulary.\n",
    "        \"\"\"\n",
    "        # This will be our output\n",
    "        x1 = self.embedding(word1)\n",
    "        x2 = self.embedding(word2)\n",
    "        x3 = self.embedding(word3)\n",
    "        y = torch.cat((x1, x2, x3), dim=-1)\n",
    "        \n",
    "#         x = torch.concatenate((word1, word2, word3))\n",
    "#         print(word1.shape)\n",
    "#         print(x.shape)\n",
    "#         y = self.embedding(x)\n",
    "        y = self.hidden(y)\n",
    "        y = self.activation(y)\n",
    "        y = self.output(y)       \n",
    "        \n",
    "        # The loss we will use later does not play well with softmax. \n",
    "        # So we only apply it for inferencing\n",
    "        if inference:\n",
    "            y = self.softmax(y)        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68515b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.689683Z",
     "start_time": "2024-05-21T12:20:24.619804Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "107e27e53aee57e5f853ba49dca85796",
     "grade": true,
     "grade_id": "test_NeuralLanguageModel2_B0",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0740,  0.0229,  0.1719,  0.0541, -0.0604,  0.1465, -0.3477, -0.1297,\n",
      "         0.2599, -0.2497,  0.2973, -0.1395, -0.1857,  0.2469,  0.0942, -0.1472,\n",
      "         0.1477, -0.2054, -0.2845, -0.3283,  0.0500, -0.2007,  0.1455, -0.2583,\n",
      "         0.0714,  0.0671, -0.2971, -0.1860,  0.2659,  0.0637,  0.1151,  0.1627,\n",
      "        -0.2914, -0.0198, -0.3259, -0.2389, -0.2950, -0.0595,  0.0064,  0.2538,\n",
      "         0.1873,  0.0719,  0.2822, -0.2693, -0.2765,  0.1144, -0.2607, -0.0305,\n",
      "         0.0829, -0.2906], grad_fn=<ViewBackward0>)\n",
      "tensor([0.0219, 0.0209, 0.0242, 0.0215, 0.0192, 0.0236, 0.0144, 0.0179, 0.0264,\n",
      "        0.0159, 0.0274, 0.0177, 0.0169, 0.0261, 0.0224, 0.0176, 0.0236, 0.0166,\n",
      "        0.0153, 0.0147, 0.0214, 0.0167, 0.0236, 0.0157, 0.0219, 0.0218, 0.0151,\n",
      "        0.0169, 0.0266, 0.0217, 0.0229, 0.0240, 0.0152, 0.0200, 0.0147, 0.0160,\n",
      "        0.0152, 0.0192, 0.0205, 0.0263, 0.0246, 0.0219, 0.0270, 0.0156, 0.0155,\n",
      "        0.0229, 0.0157, 0.0198, 0.0221, 0.0152], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# This is to test your implementation\n",
    "\n",
    "# First create the model\n",
    "vocab_size = 50\n",
    "model = NeuralLanguageModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=16,\n",
    "    hidden_size=10\n",
    ")\n",
    "\n",
    "# Next create some inputs for our model\n",
    "encoder = OneHotEncoder(vocab_size)\n",
    "\n",
    "word1, word2, word3 = encoder.encode_sequence([3, 7, 2])\n",
    "\n",
    "# Now we feed it to our model\n",
    "output = model(word1, word2, word3)\n",
    "\n",
    "print(output)\n",
    "assert output.shape[0] == vocab_size, \"Our output should have the size of the vocabulary\"\n",
    "\n",
    "# Next we do the same for inference (we check if the softmax is applied then)\n",
    "output = model(word1, word2, word3, inference=True)\n",
    "print(output)\n",
    "\n",
    "assert abs(output.sum().item() - 1) < 10e-6, \"The outputs should sum up to 1\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d1573",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba3fd369d746067a08c046aa6e71c081",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_C_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## The Dataset\n",
    "\n",
    "The dataset class was already implemented for you. Look at it and understand what it does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "158c9d99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:24.736495Z",
     "start_time": "2024-05-21T12:20:24.696262Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "327127de9c891d005e0608bfe5ae20a7",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_C_Description1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import List, Any, Tuple\n",
    "\n",
    "def sliding_window(sequence: List[Any], window_size: int) -> List[Any]:\n",
    "    \"\"\"\n",
    "    Generate a sliding window over a sequence (list).\n",
    "\n",
    "    Args:\n",
    "        sequence (list): The input sequence.\n",
    "        window_size (int): The size of the sliding window.\n",
    "\n",
    "    Yields:\n",
    "        list: A window of elements from the input sequence.\n",
    "    \"\"\"\n",
    "    for i in range(len(sequence) - window_size + 1):\n",
    "        yield sequence[i:i + window_size]\n",
    "        \n",
    "\n",
    "class NGramTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for generating trigram-based text datasets.\n",
    "\n",
    "    Args:\n",
    "        sentences (List[str]): A list of input sentences.\n",
    "        vocab_size (int, optional): The size of the vocabulary to use for tokenization.\n",
    "                                    Defaults to None.\n",
    "\n",
    "    Methods:\n",
    "        __len__(self) -> int: Returns the total number of examples in the dataset.\n",
    "\n",
    "        __getitem__(self, index: int) -> Tuple[List[int], int]:\n",
    "            Returns a tuple containing the input trigram and its corresponding label for the specified index.\n",
    "\n",
    "    Example:\n",
    "        sentences = [\"This is a sample sentence.\", \"Another example sentence.\"]\n",
    "        dataset = TrigramTextDataset(sentences, vocab_size=10000)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, sentences: List[str], vocab_size: int=None):\n",
    "        \"\"\"\n",
    "        Initializes the TrigramTextDataset with input sentences and vocabulary size.\n",
    "\n",
    "        Args:\n",
    "            sentences (List[str]): A list of input sentences.\n",
    "            vocab_size (int, optional): The size of the vocabulary to use for tokenization.\n",
    "                                        Defaults to None.\n",
    "        \"\"\"\n",
    "        # First augment the sentences with a start and end symbol\n",
    "        # We add three of each since we look at four grams\n",
    "        sentences = [\n",
    "            '<s> <s> <s>' + sentence + ' </s> </s> </s>'\n",
    "            for sentence in sentences\n",
    "        ]\n",
    "        # Next we train our tokenizer\n",
    "        self.tokenizer = tokenizer_from_strings(sentences, vocab_size)\n",
    "        self.encoder = OneHotEncoder(self.tokenizer.get_vocab_size())\n",
    "        \n",
    "        # Prepare our examples\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            # Go over each trigram of the encoded sentence\n",
    "            for trigram in sliding_window(self.tokenizer.encode(sentence).ids, 4):\n",
    "                # Take the first two tokens as input\n",
    "                self.inputs.append(trigram[:-1])\n",
    "                # Take the last token as the label\n",
    "                self.labels.append(trigram[-1])\n",
    "                \n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the total number of examples in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            int: The number of examples in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> Tuple[List[torch.tensor], torch.tensor]:\n",
    "        \"\"\"\n",
    "        Returns a tuple containing the input trigram and its corresponding label for the specified index.\n",
    "\n",
    "        Args:\n",
    "            index (int): The index of the example to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], int]: A tuple containing the input trigram (a list of integers) and\n",
    "            its corresponding label (an integer).\n",
    "        \"\"\"\n",
    "        return self.encoder.encode_sequence(self.inputs[index]), self.encoder.encode(self.labels[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a032dbc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:25.457087Z",
     "start_time": "2024-05-21T12:20:24.740925Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f1e62afd6ae18dd1805d80a2d5b2457",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_C_Description2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.]), tensor([0., 0., 0.,  ..., 0., 0., 0.])]\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Adrian Toomes and', 'his')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open our training data\n",
    "# This file has one sentence per line\n",
    "with open('/srv/shares/NLP/datasets/marvel/spider_man_homecoming.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "# Create the dataset\n",
    "dataset = NGramTextDataset(text.split(\"\\n\"))\n",
    "\n",
    "# Look at one example\n",
    "inputs, label = dataset[4]\n",
    "\n",
    "print(inputs)\n",
    "print(label)\n",
    "\n",
    "# We can also turn this back into strings using the tokenizer\n",
    "word1, word2, word3 = inputs\n",
    "\n",
    "# Turn the one-hot vectors back to indices\n",
    "indices = [\n",
    "    word1.argmax().item(),\n",
    "    word2.argmax().item(),\n",
    "    word3.argmax().item()\n",
    "]\n",
    "\n",
    "label_index = label.argmax().item()\n",
    "\n",
    "# Turn these indices back to strings\n",
    "dataset.tokenizer.decode(indices), dataset.tokenizer.decode([label_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bcf57ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:25.469913Z",
     "start_time": "2024-05-21T12:20:25.463425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(word1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff1ea1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4369b20cf1cccca31515536729316c04",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_C_Description3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model C)\n",
    "### The training loop and optimizer\n",
    "\n",
    "Please implement the training loop below. \n",
    "This method receives a model, an optimizer, a loss function and a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24233932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:25.526622Z",
     "start_time": "2024-05-21T12:20:25.473196Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0c6ab2d18ea653fa8b4864dfece3c515",
     "grade": true,
     "grade_id": "NeuralLanguageModel2_C",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from torch.optim import Optimizer\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import numpy as np\n",
    "\n",
    "def train_one_epoch(\n",
    "    model: nn.Module, \n",
    "    optimizer: Optimizer, \n",
    "    loss_fn: _Loss, \n",
    "    dataloader: DataLoader) -> float:\n",
    "    \"\"\"\n",
    "    Trains a neural network model for one epoch using the specified data.\n",
    "\n",
    "    Parameters:\n",
    "        model (nn.Module): The neural network model to be trained.\n",
    "        optimizer (Optimizer): The optimizer used for updating model weights.\n",
    "        loss_fn (_Loss): The loss function used to compute the training loss.\n",
    "        dataloader (DataLoader): The data loader providing batches of training data.\n",
    "\n",
    "    Returns:\n",
    "        float: The mean training loss for the entire epoch.\n",
    "    \"\"\"\n",
    "    batch_losses = []\n",
    "    \n",
    "    for batch_id, data in enumerate(dataloader):\n",
    "#         print(\"b\",batch_id)\n",
    "#         print(\"d\",data)\n",
    "\n",
    "        inputs, labels = data\n",
    "        word1, word2, word3 = inputs\n",
    "        print(word1)\n",
    "#         print(\"w\",word1[0])\n",
    "#         outputs = model(word1[0], word2[0], word3[0])\n",
    "\n",
    "        # We need to zero our gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, labels[0])\n",
    "\n",
    "        # Calculate gradient from loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record the loss\n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "        return np.mean(batch_losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c4a386",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1be88fed9845c2cc344acf72a37301dc",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_D_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model D)\n",
    "### Creating the optimizer, loss, model and dataloader\n",
    "\n",
    "Use a batch size of 256 for your data loader.\n",
    "\n",
    "Initialize your model with an embedding size of 8 and a hidden size of 12.\n",
    "\n",
    "Use AdamW as your optimizer with a learning rate of 0.01.\n",
    "\n",
    "Use the CrossEntropyLoss as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6a18636",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:20:25.609164Z",
     "start_time": "2024-05-21T12:20:25.532477Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22a9f0d9e0ac70dba823b90c15e5ec09",
     "grade": true,
     "grade_id": "NeuralLanguageModel2_D",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import AdamW\n",
    "\n",
    "vocab_size = dataset.tokenizer.get_vocab_size()\n",
    "\n",
    "model = NeuralLanguageModel(vocab_size= vocab_size, embedding_size=8, hidden_size=12)\n",
    "dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ee7f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "25b366cedb9c89bcfe7d424e7ba22a0a",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_E_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model E)\n",
    "### Train the model\n",
    "\n",
    "Train the model for at least 10 epochs (this should take about 3 minutes).\n",
    "\n",
    "**Hint: If you want a progress bar for your loops you can use the following code:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b0fafdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:23:31.329772Z",
     "start_time": "2024-05-21T12:20:25.616096Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "268dc182cd23c3ad45e38802a7af131c",
     "grade": true,
     "grade_id": "NeuralLanguageModel2_E",
     "locked": false,
     "points": 15,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b58ef07bec34c75af230298a29ea08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[5.05574184773015,\n",
       " 4.002994163363588,\n",
       " 3.6176302877126956,\n",
       " 3.3918839435951385,\n",
       " 3.2453005570991365,\n",
       " 3.1354138862852956,\n",
       " 3.047662863544389,\n",
       " 2.9745425605306437,\n",
       " 2.9141877655889474,\n",
       " 2.8609562714894614]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "epoch_losses = []\n",
    "\n",
    "for i in tqdm_notebook(range(10), desc=\"Processing\"):\n",
    "\n",
    "   \n",
    "    \n",
    "#     epoch_losses.append( train_one_epoch( model, \n",
    "#                     optimizer, \n",
    "#                     loss_fn, \n",
    "#                     dataloader))\n",
    "\n",
    "    batch_losses = []\n",
    "\n",
    "    for batch_id, data in enumerate(dataloader):\n",
    "#         print(\"b\",batch_id)\n",
    "#         print(\"d\",data)\n",
    "\n",
    "        inputs, labels = data\n",
    "        word1, word2, word3 = inputs\n",
    "#         print(word1)\n",
    "#         print(\"w\",word1[0])\n",
    "        outputs = model(word1, word2, word3)\n",
    "        \n",
    "        # We need to zero our gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Calculate gradient from loss\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record the loss\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    epoch_losses.append(np.mean(batch_losses))\n",
    "\n",
    "epoch_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a078566",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4825bf8c47a5f4fe0246beb1aa91742b",
     "grade": false,
     "grade_id": "NeuralLanguageModel2_F_Description0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Neural Language Model F)\n",
    "### Plot the losses\n",
    "\n",
    "Create a plot with the batch losses.\n",
    "Your x axis is the epoch, your y axis is the loss.\n",
    "\n",
    "Don't forget labels, a title and a grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c337f5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:23:31.603911Z",
     "start_time": "2024-05-21T12:23:31.332769Z"
    },
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab60650a7f573e39a3afd5e679018926",
     "grade": true,
     "grade_id": "NeuralLanguageModel2_F",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(epoch_losses)\n",
    "\n",
    "plt.grid()\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"CrossEntropy Loss\")\n",
    "plt.title(\"Loss for NeuralLanguageModel\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fac69250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T12:23:31.647820Z",
     "start_time": "2024-05-21T12:23:31.607981Z"
    },
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d22e319d24dbb5f50b0d9e3516aa80a",
     "grade": false,
     "grade_id": "cell-95573703dff4a00e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> <s> <s> No , no , no , no . </s>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can do inference\n",
    "sentence = \"<s> <s> I'm a little station on the ground\"\n",
    "\n",
    "tokenized = dataset.tokenizer.encode(sentence)\n",
    "token_ids = tokenized.ids\n",
    "\n",
    "onehots = dataset.encoder.encode_sequence(token_ids)[-3:]\n",
    "\n",
    "predicted_index = model(*onehots, inference=True).argmax().item()\n",
    "\n",
    "dataset.tokenizer.decode([predicted_index])\n",
    "\n",
    "def generate_random_sentence(model, dataset, input_sequence):\n",
    "    sentence_end = False\n",
    "    while not sentence_end:\n",
    "        tokenized = dataset.tokenizer.encode(input_sequence)\n",
    "        token_ids = tokenized.ids\n",
    "\n",
    "        onehots = dataset.encoder.encode_sequence(token_ids)[-3:]\n",
    "        \n",
    "        probabilities = model(*onehots, inference=True).detach().numpy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        next_index = np.random.choice(model.vocab_size, p=probabilities)\n",
    "        \n",
    "        # We specified <s> and </s> as special tokens. To have them be part of the output \n",
    "        # we need to set the flag skip_special_tokens=False\n",
    "        next_word = dataset.tokenizer.decode([next_index], skip_special_tokens=False)\n",
    "        sentence_end = next_word == \"</s>\"\n",
    "        input_sequence += f\" {next_word}\"\n",
    "    return input_sequence\n",
    "\n",
    "generate_random_sentence(model, dataset, \"<s> <s> <s> No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12159cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
